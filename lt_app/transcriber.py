
import numpy as np
import asyncio
import time
from faster_whisper import WhisperModel

from .ai_processing import fix_transcription_with_ai
from .config import MAX_PAUSE_THRESHOLD
from .utils import is_meaningful_text, process_final_sentence
import lt_app.config as config
transcription_running = False



# ‚úÖ Initialize the Whisper Model with optimized settings
whisper_model = WhisperModel(config.MODEL_SIZE, device=config.DEVICE, compute_type=config.COMPUTE_TYPE)


async def transcribe_audio(callback=None):
    """Continuously transcribe audio and detect sentence boundaries."""
    global transcription_running
    if transcription_running or callback is None:
        return  # ‚úÖ Prevent multiple loops
    transcription_running = True
    try:
        while True:
            if not config.RECORDING:
                await asyncio.sleep(0.5)
                continue  # üîπ Skip processing when paused
            await asyncio.sleep(1)  # üî• Adjust for responsiveness
            current_time = time.time()

            # ‚úÖ Process Mic and System Audio **at the same time**
            tasks = []

            # ‚úÖ Handle Mic Buffer if it exists
            if config.mic_buffer:
                last_audio_time = config.last_mic_audio_time
                check_time = current_time - last_audio_time
                if check_time >= MAX_PAUSE_THRESHOLD:  # Ensure enough pause
                    tasks.append(handle_transcription("mic", config.mic_buffer, callback))

            # ‚úÖ Handle System Buffer if it exists
            if config.system_buffer:
                last_audio_time = config.last_system_audio_time
                check_time = current_time - last_audio_time
                if check_time >= MAX_PAUSE_THRESHOLD:  # Ensure enough pause
                    tasks.append(handle_transcription("system", config.system_buffer, callback))
            if config.digital_buffer:
                last_audio_time = config.last_digital_audio_time
                check_time = current_time - last_audio_time
                if check_time >= MAX_PAUSE_THRESHOLD:  # Ensure enough pause
                    tasks.append(handle_transcription("digital", config.digital_buffer, callback))

            # ‚úÖ Run both transcriptions **at the same time**
            if tasks:
                await asyncio.gather(*tasks)
                
    except Exception as e:
        print(f"‚ùå Transcription loop error: {e}")


# ‚úÖ Mic & System Audio Settings

def process_transcription(source, buffer):
    """Process and transcribe audio from a given buffer."""
    try:
        audio_data = np.concatenate(buffer, axis=0).flatten()
        buffer.clear()  # ‚úÖ Clear the buffer after processing

        if np.max(np.abs(audio_data)) == 0:
            return None  # üîπ Avoid division by zero errors

        # ‚úÖ Normalize audio
        audio_data = audio_data / np.max(np.abs(audio_data))
        if source == "mic":
            config.last_transcription_mic = ""
        elif source == "system":
            config.last_transcription_system = ""
        elif source == "digital":
            config.last_transcription_digital = ""

        # üî• Transcribe with Whisper
        segments, _ = whisper_model.transcribe(audio_data)
        transcript = " ".join(segment.text for segment in segments).strip()
        if not is_meaningful_text(transcript):
            return None  # ‚úÖ Return nothing to discard the junk
        if config.FIX_TRANSCRIPTION:
            transcript = fix_transcription_with_ai(transcript)
        return transcript

    except Exception as e:
        print(f"‚ùå Transcription error ({source}): {e}")
        return None

async def handle_transcription(source, buffer, callback=None):
    """Process transcription for mic or system audio independently."""
    
    transcript = process_transcription(source, buffer)    
    if not transcript:
        if source == "mic":
            last_transcript = config.last_transcription_mic
        elif source == "system":
            last_transcript = config.last_transcription_system
        elif source == "digital":
            last_transcript = config.last_transcription_digital
                
        # If there's no last transcript, there's nothing to process, so return
        if not last_transcript:
            return
                
    if source == "mic":
        transcript = f"{config.last_transcription_mic} {transcript}".strip() if config.last_transcription_mic else transcript
        config.last_transcription_mic = transcript
        config.last_transcription_mic_time = time.time()
    elif source == "system":
        transcript = f"{config.last_transcription_system} {transcript}".strip() if config.last_transcription_system else transcript
        config.last_transcription_system = transcript
        config.last_transcription_system_time = time.time()
    elif source == "digital":
        transcript = f"{config.last_transcription_digital} {transcript}".strip
        config.last_transcription_digital_time = time.time()
        config.last_transcription_digital = transcript

    await process_final_sentence(transcript, source, callback)
        
        
